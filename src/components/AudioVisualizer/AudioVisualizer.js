// src/components/AudioVisualizer/AudioVisualizer.js - Verwaltet die Audioger√§te, initialisiert den Audiostream und rendert Visualisierungen im Canvas

import React, { useEffect, useState, useRef } from 'react';
import { setupAudio } from '../utils/audioUtils'; // Hilfsfunktion zur Audiokonfiguration
import {
  calculateVolume,
  calculatePeak,
} from '../utils/audioCalculations'; // Berechnungen f√ºr Audioanalysen
import {
  drawFrequencySpectrum,
  drawWaveform,
} from '../utils/visualizerUtils'; // Funktionen zur Visualisierung

/**
 * üéµ AudioVisualizer Komponente
 * Verwaltet den Zustand, initialisiert Audio und steuert die Visualisierungsfunktionen.
 */
function AudioVisualizer() {
  // üéß State f√ºr verf√ºgbare Audioger√§te und ausgew√§hltes Ger√§t
  const [devices, setDevices] = useState([]);
  const [selectedDevice, setSelectedDevice] = useState('');

  // üé¨ Steuert die Animation der Visualisierungen
  const [isAnimating, setIsAnimating] = useState(false);

  // üß† Refs f√ºr Audio-Analyser, Datenarrays und Canvas
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const canvasRef = useRef(null);

  // üîÅ Ref f√ºr die Animation-Frame-ID
  const animationFrameRef = useRef(null);

  // üì≤ L√§dt verf√ºgbare Audioger√§te beim Komponentenmout
  useEffect(() => {
    async function getAudioDevices() {
      const deviceList = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = deviceList.filter((device) => device.kind === 'audioinput');
      setDevices(audioInputs);

      if (audioInputs.length > 0) {
        setSelectedDevice(audioInputs[0].deviceId); // W√§hlt standardm√§√üig das erste Ger√§t aus
      }
    }
    getAudioDevices();
  }, []);

  // üé∂ Initialisiert Audio, wenn ein Ger√§t ausgew√§hlt wird
  useEffect(() => {
    if (!selectedDevice) return;

    async function initializeAudio() {
      const { analyser, dataArray } = await setupAudio(selectedDevice);
      analyserRef.current = analyser;
      dataArrayRef.current = dataArray;
    }
    initializeAudio();
  }, [selectedDevice]);

  // üé® Verwaltet die Visualisierungen basierend auf dem `isAnimating` Zustand
  useEffect(() => {
    let animationActive = false; 

    if (isAnimating) {
      console.log('Animation started');
      const canvas = canvasRef.current;
      const canvasCtx = canvas.getContext('2d');
      let volumePeak = 0;

      let lastRenderTime = 0;
      const targetFPS = 60; // Maximal 60 FPS

      // üé¨ Render-Funktion f√ºr die Animation
      function renderFrame(currentTime) {
        const timeSinceLastRender = currentTime - lastRenderTime;
        if (timeSinceLastRender < 1000 / targetFPS) {
          requestAnimationFrame(renderFrame);
          return;
        }
        lastRenderTime = currentTime;

        if (!animationActive) return; 

        // üßπ Canvas bereinigen
        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

        // üìà Berechnung der Lautst√§rke und des Peaks
        const volume = calculateVolume(dataArrayRef.current);
        volumePeak = calculatePeak(canvas.height * volume, volumePeak);

        // üîà Mindestlautst√§rkeschwelle
        const MIN_THRESHOLD = 10; 
        if (volume * 255 < MIN_THRESHOLD) { 
          canvasCtx.clearRect(0, 0, canvas.width, canvas.height); 
          requestAnimationFrame(renderFrame);
          return;
        }

        // üé® Zeichnet die Visualisierungen
        drawFrequencySpectrum(canvas, analyserRef.current);
        drawWaveform(canvas, analyserRef.current, dataArrayRef.current);

        // üéö Zeichnet die Lautst√§rkenanzeige
        canvasCtx.fillStyle = 'rgb(0, 0, 255)';
        canvasCtx.fillRect(canvas.width - 50, canvas.height - canvas.height * volume, 30, canvas.height * volume);

        // üéØ Zeichnet den Lautst√§rkenpeak
        canvasCtx.fillRect(canvas.width - 50, canvas.height - volumePeak - 5, 30, 5);

        animationFrameRef.current = requestAnimationFrame(renderFrame);
      }
      
      requestAnimationFrame(renderFrame);
      animationActive = true;

    } else {
      console.log('Animation stopped');
      animationActive = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
    } 

    // üßº Bereinigt Animationen beim Verlassen der Komponente
    return () => {
      animationActive = false;
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
    };
  }, [isAnimating]);

  // ‚ñ∂Ô∏è Startet die Visualisierung
  function startVisualizations() {
    setIsAnimating(true);
  }

  // ‚èπ Stoppt die Visualisierung
  function stopVisualizations() {
    setIsAnimating(false);
  }

  return (
    <div>
      <h1>Audio Visualizer</h1>
      
      {/* üéô Auswahl des Audioeingangs */}
      <label htmlFor="audio-input">Select Audio Input:</label>
      <select
        id="audio-input"
        value={selectedDevice}
        onChange={(e) => setSelectedDevice(e.target.value)}
      >
        {devices.map((device) => (
          <option key={device.deviceId} value={device.deviceId}>
            {device.label || `Device ${device.deviceId}`}
          </option>
        ))}
      </select>

      <div style={{ marginTop: '10px' }}>
        <button onClick={startVisualizations} style={{ marginRight: '5px' }}>
          Start
        </button>
        <button onClick={stopVisualizations}>Stop</button>
      </div>

      {/* üì∫ Canvas zur Darstellung der Visualisierungen */}
      <canvas
        ref={canvasRef}
        width="800"
        height="400"
        style={{
          border: '1px solid white',
          marginTop: '10px',
          backgroundColor: 'black',
        }}
      ></canvas>
    </div>
  );
}

export default AudioVisualizer;